{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Smartphone Activity Detector\n",
    "\n",
    "In this activity, you will train a neural network to use smartphone data to predict the activity of the user. \n",
    "\n",
    "This dataset has already been separated into input features and target activities. Additional information on the dataset can be found here. \n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "Prepare the data for the neural network. This includes splitting the data into a training and testing dataset, Scaling the data, and encoding the categorical target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043580</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.035054</td>\n",
       "      <td>-0.995381</td>\n",
       "      <td>-0.988366</td>\n",
       "      <td>-0.937382</td>\n",
       "      <td>-0.995007</td>\n",
       "      <td>-0.988816</td>\n",
       "      <td>-0.953325</td>\n",
       "      <td>-0.794796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.314848</td>\n",
       "      <td>-0.713308</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841559</td>\n",
       "      <td>0.179913</td>\n",
       "      <td>-0.051718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>-0.985973</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>-0.993135</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>-0.993825</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.043580 -0.005970 -0.035054 -0.995381 -0.988366 -0.937382 -0.995007   \n",
       "1  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "2  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "3  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "4  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.988816 -0.953325 -0.794796  ... -0.012236 -0.314848 -0.713308 -0.112754   \n",
       "1 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "2 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "3 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "4 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841559  0.179913 -0.051718  \n",
       "1 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "2  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "4  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the input features into `X`\n",
    "X = pd.read_csv(Path(\"../Resources/features.csv\"), header=None)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity\n",
       "0  standing\n",
       "1  standing\n",
       "2  standing\n",
       "3  standing\n",
       "4  standing"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the target values into `y`\n",
    "y = pd.read_csv(Path(\"../Resources/target.csv\"))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standing              1423\n",
       "laying                1413\n",
       "sitting               1293\n",
       "walking               1226\n",
       "walking_upstairs      1073\n",
       "walking_downstairs     987\n",
       "stand_to_lie            90\n",
       "sit_to_lie              75\n",
       "lie_to_sit              60\n",
       "lie_to_stand            57\n",
       "stand_to_sit            47\n",
       "sit_to_stand            23\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing input features using StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply One-hot encoding to the target labels\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "\n",
    "encoded_y_train = enc.transform(y_train).toarray()\n",
    "encoded_y_test = enc.transform(y_test).toarray()\n",
    "\n",
    "# class_values = y[\"activity\"].values.reshape(-1, 1)\n",
    "# enc.fit(class_values)\n",
    "# enc.categories_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "neuron = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
    "neuron.add(Dense(100, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "# number_hidden_nodes = 1500\n",
    "#neuron.add(Dense(100, activation=\"relu\", input_dim=number_inputs))\n",
    "# model.add(Dense(100, activation='relu', input_dim=X_train_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output layer has 12 columns that are one-hot encoded\n",
    "y_train.activity.value_counts()\n",
    "number_outputs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer using 12 output nodes. \n",
    "# HINT: Use `softmax` as the activation \n",
    "# number_classes = 561\n",
    "# neuron.add(Dense(units=number_classes, activation=\"softmax\"))\n",
    "neuron.add(Dense(number_outputs, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "neuron.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 100)               56200     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 57,412\n",
      "Trainable params: 57,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "neuron.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "183/183 - 0s - loss: 0.0527 - accuracy: 0.8721\n",
      "Epoch 2/100\n",
      "183/183 - 0s - loss: 0.0210 - accuracy: 0.9506\n",
      "Epoch 3/100\n",
      "183/183 - 0s - loss: 0.0145 - accuracy: 0.9679\n",
      "Epoch 4/100\n",
      "183/183 - 0s - loss: 0.0135 - accuracy: 0.9712\n",
      "Epoch 5/100\n",
      "183/183 - 0s - loss: 0.0088 - accuracy: 0.9801\n",
      "Epoch 6/100\n",
      "183/183 - 0s - loss: 0.0075 - accuracy: 0.9840\n",
      "Epoch 7/100\n",
      "183/183 - 0s - loss: 0.0058 - accuracy: 0.9892\n",
      "Epoch 8/100\n",
      "183/183 - 0s - loss: 0.0067 - accuracy: 0.9854\n",
      "Epoch 9/100\n",
      "183/183 - 0s - loss: 0.0057 - accuracy: 0.9885\n",
      "Epoch 10/100\n",
      "183/183 - 0s - loss: 0.0044 - accuracy: 0.9911\n",
      "Epoch 11/100\n",
      "183/183 - 0s - loss: 0.0033 - accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "183/183 - 0s - loss: 0.0036 - accuracy: 0.9935\n",
      "Epoch 13/100\n",
      "183/183 - 0s - loss: 0.0031 - accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "183/183 - 0s - loss: 0.0031 - accuracy: 0.9936\n",
      "Epoch 15/100\n",
      "183/183 - 0s - loss: 0.0025 - accuracy: 0.9936\n",
      "Epoch 16/100\n",
      "183/183 - 0s - loss: 0.0017 - accuracy: 0.9967\n",
      "Epoch 17/100\n",
      "183/183 - 0s - loss: 0.0015 - accuracy: 0.9974\n",
      "Epoch 18/100\n",
      "183/183 - 0s - loss: 0.0014 - accuracy: 0.9978\n",
      "Epoch 19/100\n",
      "183/183 - 0s - loss: 8.6802e-04 - accuracy: 0.9995\n",
      "Epoch 20/100\n",
      "183/183 - 0s - loss: 0.0011 - accuracy: 0.9983\n",
      "Epoch 21/100\n",
      "183/183 - 0s - loss: 6.5812e-04 - accuracy: 0.9997\n",
      "Epoch 22/100\n",
      "183/183 - 0s - loss: 7.4385e-04 - accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "183/183 - 0s - loss: 6.6857e-04 - accuracy: 0.9993\n",
      "Epoch 24/100\n",
      "183/183 - 0s - loss: 0.0021 - accuracy: 0.9954\n",
      "Epoch 25/100\n",
      "183/183 - 0s - loss: 0.0093 - accuracy: 0.9864\n",
      "Epoch 26/100\n",
      "183/183 - 0s - loss: 0.0078 - accuracy: 0.9842\n",
      "Epoch 27/100\n",
      "183/183 - 0s - loss: 0.0027 - accuracy: 0.9945\n",
      "Epoch 28/100\n",
      "183/183 - 0s - loss: 0.0024 - accuracy: 0.9962\n",
      "Epoch 29/100\n",
      "183/183 - 0s - loss: 4.2194e-04 - accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "183/183 - 0s - loss: 1.4865e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "183/183 - 0s - loss: 9.3744e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "183/183 - 0s - loss: 9.1092e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "183/183 - 0s - loss: 7.8391e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "183/183 - 0s - loss: 7.1654e-05 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "183/183 - 0s - loss: 6.4446e-05 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "183/183 - 0s - loss: 5.9750e-05 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "183/183 - 0s - loss: 5.2868e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "183/183 - 0s - loss: 5.0993e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "183/183 - 0s - loss: 4.4720e-05 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "183/183 - 0s - loss: 4.2381e-05 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "183/183 - 0s - loss: 4.0012e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "183/183 - 0s - loss: 3.7326e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "183/183 - 0s - loss: 3.3035e-05 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "183/183 - 0s - loss: 3.1664e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "183/183 - 0s - loss: 2.9112e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "183/183 - 0s - loss: 3.0619e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "183/183 - 0s - loss: 2.5443e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "183/183 - 0s - loss: 2.6657e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "183/183 - 0s - loss: 2.2291e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "183/183 - 0s - loss: 2.0124e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "183/183 - 0s - loss: 1.9353e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "183/183 - 0s - loss: 1.6423e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "183/183 - 0s - loss: 1.5211e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "183/183 - 0s - loss: 1.3344e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "183/183 - 0s - loss: 1.2583e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "183/183 - 0s - loss: 1.1047e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "183/183 - 0s - loss: 1.0279e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "183/183 - 0s - loss: 9.2732e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "183/183 - 0s - loss: 8.4876e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "183/183 - 0s - loss: 7.6249e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "183/183 - 0s - loss: 7.4441e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "183/183 - 0s - loss: 6.7742e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "183/183 - 0s - loss: 6.3942e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "183/183 - 0s - loss: 5.8579e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "183/183 - 0s - loss: 5.3332e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "183/183 - 0s - loss: 5.2075e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "183/183 - 0s - loss: 4.2957e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "183/183 - 0s - loss: 3.7180e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "183/183 - 0s - loss: 3.4591e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "183/183 - 0s - loss: 3.2493e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "183/183 - 0s - loss: 2.8804e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "183/183 - 0s - loss: 2.8406e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "183/183 - 0s - loss: 3.1412e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "183/183 - 0s - loss: 2.0309e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "183/183 - 0s - loss: 3.4150e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "183/183 - 0s - loss: 0.0394 - accuracy: 0.9576\n",
      "Epoch 77/100\n",
      "183/183 - 0s - loss: 0.0035 - accuracy: 0.9936\n",
      "Epoch 78/100\n",
      "183/183 - 0s - loss: 0.0031 - accuracy: 0.9957\n",
      "Epoch 79/100\n",
      "183/183 - 0s - loss: 1.8907e-04 - accuracy: 0.9998\n",
      "Epoch 80/100\n",
      "183/183 - 0s - loss: 4.7164e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "183/183 - 0s - loss: 3.4929e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "183/183 - 0s - loss: 3.0132e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "183/183 - 0s - loss: 2.5076e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "183/183 - 0s - loss: 2.2612e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "183/183 - 0s - loss: 2.1144e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "183/183 - 0s - loss: 2.0769e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "183/183 - 0s - loss: 1.7880e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "183/183 - 0s - loss: 1.6835e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "183/183 - 0s - loss: 1.5546e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "183/183 - 0s - loss: 1.4717e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "183/183 - 0s - loss: 1.4162e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "183/183 - 0s - loss: 1.2863e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "183/183 - 0s - loss: 1.2031e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "183/183 - 0s - loss: 1.1275e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "183/183 - 0s - loss: 1.0998e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "183/183 - 0s - loss: 9.9447e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "183/183 - 0s - loss: 9.5982e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "183/183 - 0s - loss: 9.1275e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "183/183 - 0s - loss: 8.1126e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "183/183 - 0s - loss: 7.6226e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c5a53839a0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "# @NOTE: Experiment with the number of training epochs to find the minimum iterations required to achieve a good accuracy\n",
    "# model = neuron.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "neuron.fit(\n",
    "    X_train_scaled,\n",
    "    encoded_y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    \n",
    "#     callbacks= [early_stopping_monitor]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 0.0267 - accuracy: 0.9706\n",
      "Loss: 0.026719270274043083, Accuracy: 0.9706488251686096\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = neuron.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# model_loss, model_accuracy = neuron.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "# print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walking_upstairs</td>\n",
       "      <td>walking_upstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walking</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walking_downstairs</td>\n",
       "      <td>walking_downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>laying</td>\n",
       "      <td>laying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walking_upstairs</td>\n",
       "      <td>walking_upstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sitting</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standing</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>walking_downstairs</td>\n",
       "      <td>walking_downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>walking_downstairs</td>\n",
       "      <td>walking_downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>walking_downstairs</td>\n",
       "      <td>walking_downstairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actual           Predicted\n",
       "0    walking_upstairs    walking_upstairs\n",
       "1             walking             walking\n",
       "2  walking_downstairs  walking_downstairs\n",
       "3              laying              laying\n",
       "4    walking_upstairs    walking_upstairs\n",
       "5             sitting             sitting\n",
       "6            standing            standing\n",
       "7  walking_downstairs  walking_downstairs\n",
       "8  walking_downstairs  walking_downstairs\n",
       "9  walking_downstairs  walking_downstairs"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predicted = neuron.predict(X_test_scaled)\n",
    "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test.activity.values,\n",
    "    \"Predicted\": predicted\n",
    "})\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            laying       1.00      0.99      1.00       331\n",
      "        lie_to_sit       0.74      0.81      0.77        21\n",
      "      lie_to_stand       0.69      0.60      0.64        15\n",
      "        sit_to_lie       0.65      0.72      0.68        18\n",
      "      sit_to_stand       0.83      1.00      0.91         5\n",
      "           sitting       0.96      0.97      0.97       355\n",
      "      stand_to_lie       0.68      0.65      0.67        20\n",
      "      stand_to_sit       1.00      0.89      0.94        18\n",
      "          standing       0.97      0.96      0.96       361\n",
      "           walking       0.99      0.99      0.99       305\n",
      "walking_downstairs       0.99      1.00      0.99       244\n",
      "  walking_upstairs       0.99      0.99      0.99       249\n",
      "\n",
      "          accuracy                           0.97      1942\n",
      "         macro avg       0.87      0.88      0.88      1942\n",
      "      weighted avg       0.97      0.97      0.97      1942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(results.Actual, results.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-7387f993e7a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a DataFrame with the history dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# # Plot the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# df.plot(y=\"loss\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the history dictionary\n",
    "df = pd.DataFrame(neuron.history, index=range(1, len(neuron.history[\"loss\"]) + 1))\n",
    "\n",
    "# # Plot the loss\n",
    "# df.plot(y=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
